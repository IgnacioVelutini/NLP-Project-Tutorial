{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Explore here"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>url</th>\n",
                            "      <th>is_spam</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>https://briefingday.us8.list-manage.com/unsubs...</td>\n",
                            "      <td>True</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>https://www.hvper.com/</td>\n",
                            "      <td>True</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>https://briefingday.com/m/v4n3i4f3</td>\n",
                            "      <td>True</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>https://briefingday.com/n/20200618/m#commentform</td>\n",
                            "      <td>False</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>https://briefingday.com/fan</td>\n",
                            "      <td>True</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                                                 url  is_spam\n",
                            "0  https://briefingday.us8.list-manage.com/unsubs...     True\n",
                            "1                             https://www.hvper.com/     True\n",
                            "2                 https://briefingday.com/m/v4n3i4f3     True\n",
                            "3   https://briefingday.com/n/20200618/m#commentform    False\n",
                            "4                        https://briefingday.com/fan     True"
                        ]
                    },
                    "execution_count": 6,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "import pandas as pd\n",
                "\n",
                "# Load the dataset from the provided URL\n",
                "url = 'https://raw.githubusercontent.com/4GeeksAcademy/NLP-project-tutorial/main/url_spam.csv'\n",
                "df = pd.read_csv(url)\n",
                "\n",
                "# Check the first few rows of the dataset\n",
                "df.head()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[nltk_data] Downloading package stopwords to\n",
                        "[nltk_data]     /Users/ignaciovelutini/nltk_data...\n",
                        "[nltk_data]   Package stopwords is already up-to-date!\n"
                    ]
                }
            ],
            "source": [
                "import re\n",
                "from nltk.corpus import stopwords\n",
                "from sklearn.feature_extraction.text import TfidfVectorizer\n",
                "import nltk\n",
                "\n",
                "# Download stopwords from NLTK\n",
                "nltk.download('stopwords')\n",
                "stop_words = stopwords.words('english')\n",
                "\n",
                "# Function to preprocess URLs\n",
                "def preprocess_url(url):\n",
                "    # Convert to lowercase and remove special characters\n",
                "    url = re.sub(r'\\W+', ' ', url.lower())\n",
                "    # Tokenize and remove stopwords\n",
                "    tokens = [word for word in url.split() if word not in stop_words]\n",
                "    return ' '.join(tokens)\n",
                "\n",
                "# Apply preprocessing to the 'url' column\n",
                "df['processed_url'] = df['url'].apply(preprocess_url)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "# Split the dataset, using 'is_spam' as the label\n",
                "X_train, X_test, y_train, y_test = train_test_split(df['processed_url'], df['is_spam'], test_size=0.2, random_state=42)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Convert URLs into numerical features using TF-IDF\n",
                "vectorizer = TfidfVectorizer()\n",
                "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
                "X_test_tfidf = vectorizer.transform(X_test)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Initial model accuracy: 0.9466666666666667\n"
                    ]
                }
            ],
            "source": [
                "from sklearn.svm import SVC\n",
                "from sklearn.metrics import accuracy_score\n",
                "\n",
                "# Create and train the SVM model\n",
                "model = SVC()\n",
                "model.fit(X_train_tfidf, y_train)\n",
                "\n",
                "# Make predictions on the test set\n",
                "y_pred = model.predict(X_test_tfidf)\n",
                "\n",
                "# Evaluate the model\n",
                "accuracy = accuracy_score(y_test, y_pred)\n",
                "print(f'Initial model accuracy: {accuracy}')\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Best hyperparameters: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n"
                    ]
                }
            ],
            "source": [
                "from sklearn.model_selection import GridSearchCV\n",
                "\n",
                "# Define the hyperparameter grid\n",
                "param_grid = {\n",
                "    'C': [0.1, 1, 10, 100, 1000],\n",
                "    'gamma': ['scale', 'auto'],\n",
                "    'kernel': ['linear', 'poly', 'rbf']\n",
                "}\n",
                "\n",
                "# Perform grid search\n",
                "grid = GridSearchCV(SVC(), param_grid)\n",
                "grid.fit(X_train_tfidf, y_train)\n",
                "\n",
                "# Get the best parameters\n",
                "print(f\"Best hyperparameters: {grid.best_params_}\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Optimized model accuracy: 0.8966666666666666\n"
                    ]
                }
            ],
            "source": [
                "# Train the optimized model with the best parameters\n",
                "opt_model = SVC(C=1000, degree=1, gamma=\"auto\", kernel=\"poly\", random_state=42)\n",
                "opt_model.fit(X_train_tfidf, y_train)\n",
                "\n",
                "# Make predictions with the optimized model\n",
                "y_pred_opt = opt_model.predict(X_test_tfidf)\n",
                "\n",
                "# Evaluate the optimized model\n",
                "accuracy_opt = accuracy_score(y_test, y_pred_opt)\n",
                "print(f'Optimized model accuracy: {accuracy_opt}')\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "['../models/svm_spam_detector_model.pkl']"
                        ]
                    },
                    "execution_count": 16,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "import os\n",
                "import joblib\n",
                "\n",
                "# Create the '../models' directory if it doesn't exist\n",
                "if not os.path.exists('../models'):\n",
                "    os.makedirs('../models')\n",
                "\n",
                "# Save the optimized model to the '../models' folder\n",
                "joblib.dump(opt_model, '../models/svm_spam_detector_model.pkl')\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.8.13 64-bit ('3.8.13')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.1"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "110cc1dee26208153f2972f08a2ad52b6a56238dc66d48e87fb757ef2996db56"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
